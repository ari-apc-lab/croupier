########
# Copyright (c) 2019 Atos Spain SA. All rights reserved.
#
# This file is part of Croupier.
#
# Croupier is free software: you can redistribute it and/or modify it
# under the terms of the Apache License, Version 2.0 (the License) License.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT ANY WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT, IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT
# OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# See README file for full disclaimer information and LICENSE file for full
# license information in the project root.
#
# @author: Javier Carnero, Jesús Gorroñogoitia
#          Atos Research & Innovation, Atos Spain S.A.
#          e-mail: javier.carnero@atos.net, jesus.gorronogoitia@atos.net
#
# blueprint_single.yaml


tosca_definitions_version: cloudify_dsl_1_3

imports:
    # to speed things up, it is possible downloading this file,
    - http://raw.githubusercontent.com/ari-apc-lab/croupier/master/resources/types/cfy_types.yaml
    # relative import of plugin.yaml that resides in the blueprint directory
    - plugin.yaml
    - inputs_def.yaml

node_templates:

    hpc_interface:
        type: croupier.nodes.InfrastructureInterface
        properties:
            config: { get_input: hpc_interface_config }
            credentials: { get_input: hpc_interface_credentials }
            external_monitor_entrypoint: { get_input: monitor_entrypoint }
            job_prefix: { get_input: job_prefix }
            base_dir: { get_input: "hpc_base_dir" }
            monitor_period: 15
            skip_cleanup: true
            #simulate: True  # COMMENT to test against a real HPC
            workdir_prefix: "single"

    single_job:
        type: croupier.nodes.Job
        properties:
            job_options:
                commands:
                - "touch test_$1.output"
                arguments:
                - script
                nodes: 1
                tasks: 1
                tasks_per_node: 1
                max_time: '00:01:00'
                partition: { get_input: partition_name }
                queue: batch
            skip_cleanup: True
            data_mover_options: { get_input: data_mover_options }
            #These are the data_mover_options:
            #workspace: wsdata #Workspace to be created in the HPC
            #upload_ATOSFR: True #Whether to invoke data mover for data upload after job execution
            #download_ATOSFR: True #Whether to invoke data mover for data download before job execution
            #upload_WRLS: True #Whether to invoke data mover for data upload after job execution
            #download_WRLS: True #Whether to invoke data mover for data download before job execution

            #cloud_user: user name to get access to the Cloud data
            #cloud_folder: y.gorronogoitia/files/ #This path is relative to the server default data path. It could point to a file
            #wrls_user: xeupmara           #user name to get access to WRLS
            #wrls_folder: /home/xeupmara  #This path is relative to the server default data path. It could point to a file

            #hpc_folder: files/ #This path is relative to HPC workspace data path. It could point to a file
            #ws_lifetime: 1 #defines the number of days between the creation of the workspace until its automatic deletion. The maximum value is 30 days.
            #grid_userkey: #GridFTP user key as content string
            #grid_usercert: #GridFTP user cert as content string
            #grid_certpass: #GridFTP user cert password as string

        relationships:
            - type: job_managed_by_interface
              target: hpc_interface

outputs:
    single_job_name:
        description: single job name in the HPC
        value: { get_attribute: [single_job, job_name] }
